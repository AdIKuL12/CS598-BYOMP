{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BYOMP-598.png](BYOMP-598.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-U05kEA6rGm",
    "outputId": "84ae2268-b455-4c1f-81d7-c624bec42689"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install --quiet transformers datasets langchain sentence-transformers faiss-cpu torch numpy pandas matplotlib tqdm chromadb accelerate langchain_experimental langchain_openai langchain_cohere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eQ1-00T-Knrv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import faiss\n",
    "from hashlib import sha256\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lJQLmqv_DtRg"
   },
   "outputs": [],
   "source": [
    "def load_quality_github_dataset():\n",
    "    splits = {\n",
    "        \"train\": \"train.jsonl\",\n",
    "    }\n",
    "    dataset = {}\n",
    "    for split, filename in splits.items():\n",
    "        with open(f\"{filename}\", \"r\", encoding=\"utf-8\") as f:\n",
    "            dataset[split] = [json.loads(line) for line in f]\n",
    "    return dataset\n",
    "\n",
    "def flatten_quality_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Flatten the QuALITY dataset to create one entry per question\n",
    "    \"\"\"\n",
    "    flattened_dataset = {}\n",
    "\n",
    "    for split_name, samples in dataset.items():\n",
    "        flattened_samples = []\n",
    "        if split_name == \"test\":\n",
    "            continue\n",
    "        for article_data in samples:\n",
    "            article = article_data[\"article\"]\n",
    "\n",
    "            for question_data in article_data[\"questions\"]:\n",
    "\n",
    "                # Convert 1-indexed gold_label to 0-indexed\n",
    "\n",
    "                gold_label_idx = question_data[\"gold_label\"] - 1\n",
    "\n",
    "                gold_label_letter = chr(65 + gold_label_idx)  # Convert to A, B, C, D\n",
    "\n",
    "                flattened_samples.append({\n",
    "                    \"article\": article,\n",
    "                    \"question\": question_data[\"question\"],\n",
    "                    \"options\": question_data[\"options\"],\n",
    "                    \"gold_label\": gold_label_letter,  # Store as A, B, C, D\n",
    "                    \"article_id\": article_data[\"article_id\"],\n",
    "                    \"title\": article_data.get(\"title\", \"\")\n",
    "                })\n",
    "\n",
    "        flattened_dataset[split_name] = flattened_samples\n",
    "\n",
    "    return flattened_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "def load_wikiqa_dataset():\n",
    "    dataset = load_dataset(\"wiki_qa\")\n",
    "    \n",
    "    # WikiQA has different structure - we need to adapt it to our format\n",
    "    formatted_data = {\"train\": [], \"validation\": [], \"test\": []}\n",
    "    \n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        for example in dataset[split]:\n",
    "            # Create fake \"article\" from question and candidate sentences\n",
    "            context = f\"Question: {example['question']}\\n\" + \"\\n\".join(example['candidate_sentences'])\n",
    "            \n",
    "            formatted_data[split].append({\n",
    "                \"article\": context,\n",
    "                \"question\": example['question'],\n",
    "                \"options\": example['candidate_sentences'],\n",
    "                \"gold_label\": chr(65 + example['label']) if 'label' in example else None,\n",
    "                \"article_id\": example['question_id'],\n",
    "                \"title\": \"\"\n",
    "            })\n",
    "    \n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset\n",
    "\n",
    "def load_squad():\n",
    "    \"\"\"Load and preprocess SQuAD v1.1 dataset\"\"\"\n",
    "    dataset = load_dataset(\"squad\")\n",
    "    \n",
    "    formatted_data = {\"train\": []}\n",
    "    \n",
    "    for split in [\"train\"]:\n",
    "        for example in dataset[split]:\n",
    "            # SQuAD is extractive QA - create multiple choice format\n",
    "            context = example['context']\n",
    "            question = example['question']\n",
    "            \n",
    "            # Get the correct answer\n",
    "            answer_text = example['answers']['text'][0]  # Correct Answer text\n",
    "            \n",
    "            # Generate distractors from context\n",
    "            sentences = [s.strip() for s in context.split('.') if s.strip()]\n",
    "            # Filter out sentences containing the answer to avoid confusion\n",
    "            distractor_candidates = [s for s in sentences if answer_text not in s]\n",
    "            \n",
    "            # If we don't have enough distractors, create some\n",
    "            if len(distractor_candidates) < 3:\n",
    "                while len(distractor_candidates) < 3:\n",
    "                    distractor_candidates.append(f\"Incorrect option {len(distractor_candidates)+1}\")\n",
    "            \n",
    "            # Sample 3 distractors\n",
    "            distractors = random.sample(distractor_candidates, 3)\n",
    "            \n",
    "            # Randomly place the correct answer among options\n",
    "            correct_option_index = random.randint(0, 3)\n",
    "            options = []\n",
    "            \n",
    "            for i in range(4):\n",
    "                if i == correct_option_index:\n",
    "                    options.append(answer_text)\n",
    "                else:\n",
    "                    options.append(distractors.pop(0))\n",
    "            \n",
    "            # Convert index to letter (0->A, 1->B, etc.)\n",
    "            correct_option_label = chr(65 + correct_option_index)  # A, B, C, or D\n",
    "            \n",
    "            formatted_data[split].append({\n",
    "                \"article\": context,\n",
    "                \"question\": question,\n",
    "                \"options\": options,\n",
    "                \"gold_label\": correct_option_label,\n",
    "                \"article_id\": example['id'],\n",
    "                \"title\": example['title']\n",
    "            })\n",
    "    \n",
    "    return formatted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "id": "k6mOyvxGDvx-",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chunking Strategies\n",
    "class ChunkingStrategies:\n",
    "    def __init__(self, semantic_model_name=\"all-MiniLM-L6-v2\", provider_name=\"huggingface\"):\n",
    "        # Initialize embedding model for semantic chunking\n",
    "        if provider_name==\"huggingface\":\n",
    "          #self.embeddings = HuggingFaceEmbeddings(model_name= semantic_model_name) \n",
    "           self.embeddings = HuggingFaceBgeEmbeddings(\n",
    "                model_name=semantic_model_name,\n",
    "                model_kwargs={'device': 'cuda'},\n",
    "                encode_kwargs={'normalize_embeddings': True}  # Critical for BGE\n",
    "            )\n",
    "        elif provider_name==\"openai\":\n",
    "          self.embeddings = OpenAIEmbeddings()\n",
    "    def fixed_size_no_overlap(self, text, chunk_size=512):\n",
    "        \"\"\"Fixed-size chunking with no overlap\"\"\"\n",
    "        splitter = TokenTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=0\n",
    "        )\n",
    "        return splitter.split_text(text)\n",
    "\n",
    "    def fixed_size_with_overlap_10(self, text, chunk_size=512):\n",
    "        \"\"\"Fixed-size chunking with 10% overlap\"\"\"\n",
    "        overlap = int(chunk_size * 0.1)\n",
    "        splitter = TokenTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=overlap\n",
    "        )\n",
    "        return splitter.split_text(text)\n",
    "\n",
    "    def fixed_size_with_overlap_20(self, text, chunk_size=512):\n",
    "        \"\"\"Fixed-size chunking with 20% overlap\"\"\"\n",
    "        overlap = int(chunk_size * 0.2)\n",
    "        splitter = TokenTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=overlap\n",
    "        )\n",
    "        return splitter.split_text(text)\n",
    "\n",
    "    def semantic_chunking(self, text):\n",
    "        \"\"\"Semantic chunking using LangChain's SemanticChunker\"\"\"\n",
    "        try:\n",
    "            splitter = SemanticChunker(self.embeddings)\n",
    "            return splitter.split_text(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in semantic chunking: {e}\")\n",
    "            # Fallback to fixed-size chunking if semantic chunking fails\n",
    "            return self.fixed_size_with_overlap_10(text)\n",
    "\n",
    "    def sentence_based_chunking(self, text):\n",
    "        \"\"\"Sentence-based chunking\"\"\"\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \";\", \":\", \" \", \"\"],\n",
    "            chunk_size=512,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        return splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qWlvCTRpIHpa"
   },
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "    def __init__(self, model_name=\"BAAI/bge-large-en\", provider=\"huggingface\"):\n",
    "        \"\"\"\n",
    "        Initialize embedding generator using LangChain's interface\n",
    "\n",
    "        Parameters:\n",
    "            model_name (str): Name of the model to use\n",
    "            provider (str): Provider - 'huggingface', 'openai', 'cohere', etc.\n",
    "        \"\"\"\n",
    "        if provider == \"huggingface\":\n",
    "            self.embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"},\n",
    "                encode_kwargs={\"normalize_embeddings\": True}\n",
    "            )\n",
    "        elif provider == \"openai\":\n",
    "            self.embeddings = OpenAIEmbeddings(model=model_name)\n",
    "        elif provider == \"cohere\":\n",
    "            self.embeddings = CohereEmbeddings(model=model_name)\n",
    "\n",
    "    def generate_embeddings(self, chunks):\n",
    "        \"\"\"Generate embeddings for a list of text chunks\"\"\"\n",
    "        embeddings = self.embeddings.embed_documents(chunks)\n",
    "        return np.array(embeddings, dtype=np.float32) if isinstance(embeddings, list) else embeddings\n",
    "\n",
    "    def generate_question_embedding(self, question):\n",
    "        \"\"\"Generate embedding for a single question\"\"\"\n",
    "        q_embedding = self.embeddings.embed_query(question)\n",
    "        return np.array(q_embedding, dtype=np.float32) if isinstance(q_embedding, list) else q_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lx-HbhGhIQMh"
   },
   "outputs": [],
   "source": [
    "# Vector Database\n",
    "class VectorDatabase:\n",
    "    def __init__(self, dimension):\n",
    "        \"\"\"\n",
    "        Initialize a FAISS vector database with the specified dimension\n",
    "        \"\"\"\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.texts = []  # Store original texts\n",
    "        self.seen_hashes = set()\n",
    "\n",
    "    def add_embeddings(self, embeddings, texts):\n",
    "        \"\"\"\n",
    "        Add embeddings and their corresponding texts to the database\n",
    "        \"\"\"\n",
    "        if len(embeddings) == 0:\n",
    "            return\n",
    "        unique_emb = []\n",
    "        unique_texts = []\n",
    "        for emb, text in zip(embeddings, texts):\n",
    "            text_hash = sha256(text.encode()).hexdigest()\n",
    "            if text_hash not in self.seen_hashes:\n",
    "                self.seen_hashes.add(text_hash)\n",
    "                unique_emb.append(emb)\n",
    "                unique_texts.append(text)\n",
    "\n",
    "        # Convert to numpy array if it's not already\n",
    "        if isinstance(unique_emb[0], torch.Tensor):\n",
    "            unique_emb = [e.cpu().numpy() for e in unique_emb]\n",
    "\n",
    "        # Add to FAISS index\n",
    "        self.index.add(np.array(unique_emb).astype('float32'))\n",
    "\n",
    "        # Store original texts\n",
    "        self.texts.extend(unique_texts)\n",
    "\n",
    "    def search(self, query_embedding, k=3):\n",
    "        \"\"\"\n",
    "        Search for the k nearest neighbors of the query embedding\n",
    "        Returns distances and indices\n",
    "        \"\"\"\n",
    "        if isinstance(query_embedding, torch.Tensor):\n",
    "            query_embedding = query_embedding.cpu().numpy()\n",
    "\n",
    "        # Reshape if it's a single embedding\n",
    "        if len(query_embedding.shape) == 1:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "\n",
    "        # Search\n",
    "        distances, indices = self.index.search(\n",
    "            np.array(query_embedding).astype('float32'), k\n",
    "        )\n",
    "\n",
    "        # Get the corresponding texts\n",
    "        results = []\n",
    "        for idx_list in indices:\n",
    "            texts = [self.texts[idx] for idx in idx_list if idx < len(self.texts)]\n",
    "            results.append(texts)\n",
    "\n",
    "        return distances, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hhdh4ne-IaLO"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import re\n",
    "\n",
    "class LLMGenerator:\n",
    "    def __init__(self, model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token  # Set pad token\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "\n",
    "    def generate_answer(self, context, question):\n",
    "        # Format the prompt using the correct chat template\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Given the context below, respond with ONLY the letter (A, B, C, or D) of the correct answer.\\n\\nContext: {context}\\n\\nQuestion: {question}\"}\n",
    "        ]\n",
    "        prompt = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        # Tokenize and get input length\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        input_length = inputs.input_ids.shape[1]  # Get input token count\n",
    "        \n",
    "        # Generate only new tokens\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1,  # Only generate 1 new token\n",
    "                temperature=0.1,\n",
    "                top_p=0.9,\n",
    "                do_sample=True\n",
    "            )\n",
    "        \n",
    "        # Extract ONLY the new tokens (skip input tokens)\n",
    "        new_tokens = outputs[0][input_length:]\n",
    "        response = self.tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
    "        return response.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Xv36B_DEIiay"
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def evaluate_answer(self, generated_answer, gold_answer, question_type=\"multiple_choice\"):\n",
    "        \"\"\"\n",
    "        Evaluate the generated answer against the gold answer\n",
    "        gold_answer should be a letter (A, B, C, D)\n",
    "        \"\"\"\n",
    "        if question_type == \"multiple_choice\":\n",
    "            # Extract the letter choice from the generated answer\n",
    "            match = re.search(r'[A-D]', generated_answer)\n",
    "            if match:\n",
    "                predicted_choice = match.group(0)\n",
    "                correct = predicted_choice == gold_answer\n",
    "            else:\n",
    "                # If no letter is found, count as incorrect\n",
    "                correct = False\n",
    "\n",
    "            return {\n",
    "                \"accuracy\": 1.0 if correct else 0.0\n",
    "            }\n",
    "        else:\n",
    "            # For open-ended questions (not applicable for QuALITY)\n",
    "            return {\n",
    "                \"semantic_similarity\": 0.5  # Placeholder\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_generate_and_save_vector_db(dataset, strategy_name, embedding_model_name=\"BAAI/bge-large-en\", \n",
    "                               semantic_model_name=\"BAAI/bge-m3\", num_samples=100, \n",
    "                               save_dir=\"vector_dbs\", force_rebuild=False):\n",
    "    \"\"\"\n",
    "    Generate a vector database for a specific chunking strategy and save it to disk,\n",
    "    with text-based metrics output.\n",
    "\n",
    "    Parameters:\n",
    "        dataset: The flattened dataset containing documents\n",
    "        strategy_name: Name of the specific chunking strategy to use\n",
    "        embedding_model_name: Name of the embedding model to use\n",
    "        semantic_model_name: Name of semantic model to use for semantic chunking strategy\n",
    "        num_samples: Number of samples to process from training set\n",
    "        save_dir: Directory to save the vector database\n",
    "        force_rebuild: Whether to rebuild database even if it already exists\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with the database path and metrics summary\n",
    "    \"\"\"\n",
    "    print(\"WARNING: This is not the function generate and save db for all strategies, this function will not generate and save eval graphs, it will just rebuild return the metrics for select strategy.\")\n",
    "    # Initialize components\n",
    "    chunking_strategies_obj = ChunkingStrategies(semantic_model_name=semantic_model_name)\n",
    "    embedding_generator = EmbeddingGenerator(embedding_model_name)\n",
    "    \n",
    "    # Validate the strategy name\n",
    "    chunking_methods = {\n",
    "        \"fixed_size_no_overlap\": chunking_strategies_obj.fixed_size_no_overlap,\n",
    "        \"fixed_size_with_overlap_10\": chunking_strategies_obj.fixed_size_with_overlap_10,\n",
    "        \"fixed_size_with_overlap_20\": chunking_strategies_obj.fixed_size_with_overlap_20,\n",
    "        \"semantic_chunking\": chunking_strategies_obj.semantic_chunking,\n",
    "        \"sentence_based_chunking\": chunking_strategies_obj.sentence_based_chunking\n",
    "    }\n",
    "    \n",
    "    if strategy_name not in chunking_methods:\n",
    "        raise ValueError(f\"Invalid strategy name: {strategy_name}. Available strategies: {list(chunking_methods.keys())}\")\n",
    "    \n",
    "    # Create save directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate file path for the vector database\n",
    "    filename = f\"{strategy_name}_{embedding_model_name.replace('/', '_')}_{num_samples}.pkl\"\n",
    "    db_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    # Skip if database already exists and force_rebuild is False\n",
    "    if os.path.exists(db_path) and not force_rebuild:\n",
    "        print(f\"Vector database for {strategy_name} already exists at {db_path}. Skipping...\")\n",
    "        return {\"db_path\": db_path}\n",
    "    \n",
    "    print(f\"Building vector database for {strategy_name}...\")\n",
    "    \n",
    "    # Get training samples\n",
    "    train_samples = dataset[\"train\"][:num_samples]\n",
    "    \n",
    "    # Initialize metrics tracking\n",
    "    all_chunks = []\n",
    "    all_embeddings = []\n",
    "    total_chunks = 0\n",
    "    total_chunking_time = 0\n",
    "    total_embedding_time = 0\n",
    "    chunk_sizes = []\n",
    "    chunking_times = []\n",
    "    embedding_times = []\n",
    "    chunks_per_doc = []\n",
    "    \n",
    "    # Process each sample\n",
    "    chunking_method = chunking_methods[strategy_name]\n",
    "    for sample_idx, sample in enumerate(tqdm(train_samples, desc=f\"Processing {strategy_name}\")):\n",
    "        context = sample[\"article\"]\n",
    "        \n",
    "        # Apply chunking\n",
    "        start_time = time.time()\n",
    "        chunks = chunking_method(context)\n",
    "        chunking_time = time.time() - start_time\n",
    "        \n",
    "        # Generate embeddings\n",
    "        start_time = time.time()\n",
    "        chunk_embeddings = embedding_generator.generate_embeddings(chunks)\n",
    "        embedding_time = time.time() - start_time\n",
    "        \n",
    "        # Collect results\n",
    "        all_chunks.extend(chunks)\n",
    "        all_embeddings.extend(chunk_embeddings)\n",
    "        \n",
    "        # Update metrics\n",
    "        chunk_count = len(chunks)\n",
    "        total_chunks += chunk_count\n",
    "        total_chunking_time += chunking_time\n",
    "        total_embedding_time += embedding_time\n",
    "        chunk_sizes.extend([len(chunk) for chunk in chunks])\n",
    "        chunking_times.append(chunking_time)\n",
    "        embedding_times.append(embedding_time)\n",
    "        chunks_per_doc.append(chunk_count)\n",
    "        \n",
    "        # Print progress every 10 samples\n",
    "        if (sample_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {sample_idx + 1}/{len(train_samples)} samples\")\n",
    "    \n",
    "    # Create vector database\n",
    "    if len(all_embeddings) > 0:\n",
    "        # Get dimension from first embedding\n",
    "        if isinstance(all_embeddings[0], list):\n",
    "            dimension = len(all_embeddings[0])\n",
    "        else:\n",
    "            dimension = all_embeddings[0].shape[0]\n",
    "        \n",
    "        # Create and populate vector database\n",
    "        vector_db = VectorDatabase(dimension=dimension)\n",
    "        vector_db.add_embeddings(all_embeddings, all_chunks)\n",
    "        \n",
    "        # Save vector database to disk\n",
    "        with open(db_path, 'wb') as f:\n",
    "            pickle.dump(vector_db, f)\n",
    "        \n",
    "        # Calculate and print metrics\n",
    "        avg_chunks_per_doc = total_chunks / len(train_samples)\n",
    "        avg_chunk_size = np.mean(chunk_sizes) if chunk_sizes else 0\n",
    "        avg_chunking_time = np.mean(chunking_times) if chunking_times else 0\n",
    "        avg_embedding_time = np.mean(embedding_times) if embedding_times else 0\n",
    "        time_per_chunk = total_embedding_time / total_chunks if total_chunks > 0 else 0\n",
    "        \n",
    "        # Print metrics summary\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"METRICS SUMMARY FOR {strategy_name}\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Total documents processed: {len(train_samples)}\")\n",
    "        print(f\"Total chunks generated: {total_chunks}\")\n",
    "        print(f\"Average chunks per document: {avg_chunks_per_doc:.2f}\")\n",
    "        print(f\"Average chunk size: {avg_chunk_size:.2f} characters\")\n",
    "        print(f\"Min chunk size: {min(chunk_sizes) if chunk_sizes else 0} characters\")\n",
    "        print(f\"Max chunk size: {max(chunk_sizes) if chunk_sizes else 0} characters\")\n",
    "        print(f\"Total chunking time: {total_chunking_time:.2f} seconds\")\n",
    "        print(f\"Total embedding time: {total_embedding_time:.2f} seconds\")\n",
    "        print(f\"Average chunking time per document: {avg_chunking_time:.4f} seconds\")\n",
    "        print(f\"Average embedding time per document: {avg_embedding_time:.4f} seconds\")\n",
    "        print(f\"Average time per chunk: {time_per_chunk:.4f} seconds\")\n",
    "        print(f\"Vector database saved to: {db_path}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Return metrics as a dictionary\n",
    "        metrics = {\n",
    "            \"db_path\": db_path,\n",
    "            \"total_chunks\": total_chunks,\n",
    "            \"avg_chunks_per_doc\": avg_chunks_per_doc,\n",
    "            \"avg_chunk_size\": avg_chunk_size,\n",
    "            \"min_chunk_size\": min(chunk_sizes) if chunk_sizes else 0,\n",
    "            \"max_chunk_size\": max(chunk_sizes) if chunk_sizes else 0,\n",
    "            \"total_chunking_time\": total_chunking_time,\n",
    "            \"total_embedding_time\": total_embedding_time,\n",
    "            \"avg_chunking_time\": avg_chunking_time,\n",
    "            \"avg_embedding_time\": avg_embedding_time,\n",
    "            \"time_per_chunk\": time_per_chunk\n",
    "        }        \n",
    "        return metrics\n",
    "    else:\n",
    "        print(f\"No embeddings generated for {strategy_name}. Skipping database creation.\")\n",
    "        return {\"db_path\": None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "syij7QVCUxeE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_and_save_vector_dbs(dataset, embedding_model_name=\"BAAI/bge-large-en\",semantic_model_name=\"BAAI/bge-m3\",  chunking_strategies=None,\n",
    "                                 num_samples=100, save_dir=\"vector_dbs\", force_rebuild=False):\n",
    "    \"\"\"\n",
    "    Generate vector databases for each chunking strategy and save them to disk, \n",
    "    along with metrics visualization for performance analysis.\n",
    "\n",
    "    Parameters:\n",
    "        dataset: The flattened dataset containing documents\n",
    "        embedding_model_name: Name of the embedding model to use\n",
    "        semantic_model_name: Name of semantic model to use for semantic chunking strategy\n",
    "        chunking_strategies: List of chunking strategies to evaluate (if None, uses all available)\n",
    "        num_samples: Number of samples to process from training set\n",
    "        save_dir: Directory to save the vector databases\n",
    "        force_rebuild: Whether to rebuild databases even if they already exist\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping strategy names to their saved file paths and metrics plots\n",
    "    \"\"\"\n",
    "    # Initialize components\n",
    "    chunking_strategies_obj = ChunkingStrategies(semantic_model_name = semantic_model_name)\n",
    "    embedding_generator = EmbeddingGenerator(embedding_model_name)\n",
    "    generated_db = False\n",
    "    # Define chunking methods if not provided\n",
    "    if chunking_strategies is None:\n",
    "        chunking_strategies = [\n",
    "            \"fixed_size_no_overlap\",\n",
    "            \"fixed_size_with_overlap_10\",\n",
    "            \"fixed_size_with_overlap_20\",\n",
    "            \"semantic_chunking\",\n",
    "            \"sentence_based_chunking\"\n",
    "        ]\n",
    "\n",
    "    # Create save directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create metrics directory\n",
    "    metrics_dir = os.path.join(save_dir, \"metrics\")\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "    # Mapping between strategy names and methods\n",
    "    chunking_methods = {\n",
    "        \"fixed_size_no_overlap\": chunking_strategies_obj.fixed_size_no_overlap,\n",
    "        \"fixed_size_with_overlap_10\": chunking_strategies_obj.fixed_size_with_overlap_10,\n",
    "        \"fixed_size_with_overlap_20\": chunking_strategies_obj.fixed_size_with_overlap_20,\n",
    "        \"semantic_chunking\": chunking_strategies_obj.semantic_chunking,\n",
    "        \"sentence_based_chunking\": chunking_strategies_obj.sentence_based_chunking\n",
    "    }\n",
    "\n",
    "    # File paths for each vector database\n",
    "    db_paths = {}\n",
    "    for strategy in chunking_strategies:\n",
    "        # Generate a unique filename based on strategy, model, and sample count\n",
    "        filename = f\"{strategy}_{embedding_model_name.replace('/', '_')}_{num_samples}.pkl\"\n",
    "        db_paths[strategy] = os.path.join(save_dir, filename)\n",
    "    \n",
    "    # Initialize metrics tracking data structures\n",
    "    metrics = {\n",
    "        \"strategy\": [],\n",
    "        \"sample_idx\": [],\n",
    "        \"num_chunks\": [],\n",
    "        \"avg_chunk_size\": [],\n",
    "        \"max_chunk_size\": [],\n",
    "        \"min_chunk_size\": [],\n",
    "        \"chunking_time\": [],\n",
    "        \"embedding_time\": [],\n",
    "        \"time_per_chunk\": [],\n",
    "        \"total_processing_time\": []\n",
    "    }\n",
    "    \n",
    "    # Strategy summary metrics\n",
    "    strategy_metrics = defaultdict(lambda: {\n",
    "        \"total_chunks\": 0,\n",
    "        \"total_chunking_time\": 0,\n",
    "        \"total_embedding_time\": 0,\n",
    "        \"num_documents\": 0,\n",
    "        \"chunk_sizes\": [],\n",
    "        \"chunking_times\": [],\n",
    "        \"embedding_times\": [],\n",
    "        \"chunks_per_doc\": []\n",
    "    })\n",
    "\n",
    "    # Generate and save vector databases\n",
    "    for strategy in chunking_strategies:\n",
    "        db_path = db_paths[strategy]\n",
    "\n",
    "        # Skip if database already exists and force_rebuild is False\n",
    "        if os.path.exists(db_path) and not force_rebuild:\n",
    "            print(f\"Vector database for {strategy} already exists at {db_path}. Skipping...\")\n",
    "            continue\n",
    "    \n",
    "        print(f\"Building vector database for {strategy}...\")\n",
    "        generated_db = True\n",
    "        # Get training samples\n",
    "        train_samples = dataset[\"train\"][:num_samples]\n",
    "\n",
    "        # Process each sample\n",
    "        all_chunks = []\n",
    "        all_embeddings = []\n",
    "\n",
    "        # Process metrics\n",
    "        total_chunks = 0\n",
    "        total_chunking_time = 0\n",
    "        total_embedding_time = 0\n",
    "\n",
    "        for sample_idx, sample in enumerate(tqdm(train_samples, desc=f\"Processing {strategy}\")):\n",
    "            context = sample[\"article\"]\n",
    "\n",
    "            # Apply chunking\n",
    "            chunking_method = chunking_methods[strategy]\n",
    "            start_time = time.time()\n",
    "            chunks = chunking_method(context)\n",
    "            chunking_time = time.time() - start_time\n",
    "\n",
    "            # Generate embeddings\n",
    "            start_time = time.time()\n",
    "            chunk_embeddings = embedding_generator.generate_embeddings(chunks)\n",
    "            embedding_time = time.time() - start_time\n",
    "\n",
    "            # Collect results\n",
    "            all_chunks.extend(chunks)\n",
    "            all_embeddings.extend(chunk_embeddings)\n",
    "\n",
    "            # Calculate chunk sizes\n",
    "            chunk_sizes = [len(chunk) for chunk in chunks]\n",
    "            avg_chunk_size = np.mean(chunk_sizes) if chunks else 0\n",
    "            max_chunk_size = max(chunk_sizes) if chunks else 0\n",
    "            min_chunk_size = min(chunk_sizes) if chunks else 0\n",
    "\n",
    "            # Update detailed metrics\n",
    "            metrics[\"strategy\"].append(strategy)\n",
    "            metrics[\"sample_idx\"].append(sample_idx)\n",
    "            metrics[\"num_chunks\"].append(len(chunks))\n",
    "            metrics[\"avg_chunk_size\"].append(avg_chunk_size)\n",
    "            metrics[\"max_chunk_size\"].append(max_chunk_size)\n",
    "            metrics[\"min_chunk_size\"].append(min_chunk_size)\n",
    "            metrics[\"chunking_time\"].append(chunking_time)\n",
    "            metrics[\"embedding_time\"].append(embedding_time)\n",
    "            metrics[\"time_per_chunk\"].append(embedding_time / len(chunks) if chunks else 0)\n",
    "            metrics[\"total_processing_time\"].append(chunking_time + embedding_time)\n",
    "\n",
    "            # Update strategy summary metrics\n",
    "            strategy_metrics[strategy][\"total_chunks\"] += len(chunks)\n",
    "            strategy_metrics[strategy][\"total_chunking_time\"] += chunking_time\n",
    "            strategy_metrics[strategy][\"total_embedding_time\"] += embedding_time\n",
    "            strategy_metrics[strategy][\"num_documents\"] += 1\n",
    "            strategy_metrics[strategy][\"chunk_sizes\"].extend(chunk_sizes)\n",
    "            strategy_metrics[strategy][\"chunking_times\"].append(chunking_time)\n",
    "            strategy_metrics[strategy][\"embedding_times\"].append(embedding_time)\n",
    "            strategy_metrics[strategy][\"chunks_per_doc\"].append(len(chunks))\n",
    "\n",
    "            # Update running totals\n",
    "            total_chunks += len(chunks)\n",
    "            total_chunking_time += chunking_time\n",
    "            total_embedding_time += embedding_time\n",
    "\n",
    "        # Create vector database\n",
    "        if len(all_embeddings) > 0:\n",
    "            # Get dimension from first embedding\n",
    "            if isinstance(all_embeddings[0], list):\n",
    "                dimension = len(all_embeddings[0])\n",
    "            else:\n",
    "                dimension = all_embeddings[0].shape[0]\n",
    "\n",
    "            # Create and populate vector database\n",
    "            vector_db = VectorDatabase(dimension=dimension)\n",
    "            vector_db.add_embeddings(all_embeddings, all_chunks)\n",
    "\n",
    "            # Save vector database to disk\n",
    "            with open(db_path, 'wb') as f:\n",
    "                pickle.dump(vector_db, f)\n",
    "\n",
    "            print(f\"Vector database for {strategy} saved to {db_path}\")\n",
    "            print(f\"  Total chunks: {total_chunks}, Avg chunks per doc: {total_chunks/len(train_samples):.2f}\")\n",
    "            print(f\"  Total chunking time: {total_chunking_time:.2f}s\")\n",
    "            print(f\"  Total embedding time: {total_embedding_time:.2f}s\")\n",
    "        else:\n",
    "            print(f\"No embeddings generated for {strategy}. Skipping database creation.\")\n",
    "    if not generated_db:\n",
    "       return {\n",
    "        \"db_paths\": db_paths,\n",
    "        }\n",
    "    # Convert metrics to DataFrame for easier analysis\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    # Save detailed metrics to CSV\n",
    "    metrics_csv_path = os.path.join(metrics_dir, f\"chunking_metrics_{embedding_model_name.replace('/', '_')}_{num_samples}.csv\")\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "    \n",
    "    # Create and save plots\n",
    "    plot_paths = {}\n",
    "    \n",
    "    # 1. Average Chunking Time by Strategy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    strategies = list(strategy_metrics.keys())\n",
    "    avg_chunking_times = [np.mean(strategy_metrics[s][\"chunking_times\"]) for s in strategies]\n",
    "    \n",
    "    plt.bar(strategies, avg_chunking_times)\n",
    "    plt.title('Average Chunking Time by Strategy')\n",
    "    plt.xlabel('Chunking Strategy')\n",
    "    plt.ylabel('Average Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    chunking_time_plot = os.path.join(metrics_dir, f\"chunking_time_{embedding_model_name.replace('/', '_')}_{num_samples}.png\")\n",
    "    plt.savefig(chunking_time_plot)\n",
    "    plot_paths[\"chunking_time\"] = chunking_time_plot\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Average Embedding Time by Strategy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    avg_embedding_times = [np.mean(strategy_metrics[s][\"embedding_times\"]) for s in strategies]\n",
    "    \n",
    "    plt.bar(strategies, avg_embedding_times)\n",
    "    plt.title('Average Embedding Time by Strategy')\n",
    "    plt.xlabel('Chunking Strategy')\n",
    "    plt.ylabel('Average Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    embedding_time_plot = os.path.join(metrics_dir, f\"embedding_time_{embedding_model_name.replace('/', '_')}_{num_samples}.png\")\n",
    "    plt.savefig(embedding_time_plot)\n",
    "    plot_paths[\"embedding_time\"] = embedding_time_plot\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Average Number of Chunks per Document by Strategy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    avg_chunks_per_doc = [np.mean(strategy_metrics[s][\"chunks_per_doc\"]) for s in strategies]\n",
    "    \n",
    "    plt.bar(strategies, avg_chunks_per_doc)\n",
    "    plt.title('Average Number of Chunks per Document by Strategy')\n",
    "    plt.xlabel('Chunking Strategy')\n",
    "    plt.ylabel('Average Number of Chunks')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    chunks_plot = os.path.join(metrics_dir, f\"chunks_per_doc_{embedding_model_name.replace('/', '_')}_{num_samples}.png\")\n",
    "    plt.savefig(chunks_plot)\n",
    "    plot_paths[\"chunks_per_doc\"] = chunks_plot\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Average Chunk Size by Strategy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    avg_chunk_sizes = [np.mean(strategy_metrics[s][\"chunk_sizes\"]) for s in strategies]\n",
    "    \n",
    "    plt.bar(strategies, avg_chunk_sizes)\n",
    "    plt.title('Average Chunk Size by Strategy')\n",
    "    plt.xlabel('Chunking Strategy')\n",
    "    plt.ylabel('Average Chunk Size (characters)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    chunk_size_plot = os.path.join(metrics_dir, f\"chunk_size_{embedding_model_name.replace('/', '_')}_{num_samples}.png\")\n",
    "    plt.savefig(chunk_size_plot)\n",
    "    plot_paths[\"chunk_size\"] = chunk_size_plot\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Chunking Time vs. Number of Chunks Scatter Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        plt.scatter(\n",
    "            strategy_metrics[strategy][\"chunks_per_doc\"],\n",
    "            strategy_metrics[strategy][\"chunking_times\"],\n",
    "            label=strategy,\n",
    "            alpha=0.7\n",
    "        )\n",
    "    \n",
    "    plt.title('Chunking Time vs Number of Chunks')\n",
    "    plt.xlabel('Number of Chunks')\n",
    "    plt.ylabel('Chunking Time (seconds)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    scatter_plot = os.path.join(metrics_dir, f\"chunking_vs_chunks_{embedding_model_name.replace('/', '_')}_{num_samples}.png\")\n",
    "    plt.savefig(scatter_plot)\n",
    "    plot_paths[\"chunking_vs_chunks\"] = scatter_plot\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Processing Time Distribution (Stacked Bar)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    x = np.arange(len(strategies))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Calculate average times for each strategy\n",
    "    avg_chunking = [np.mean(strategy_metrics[s][\"chunking_times\"]) for s in strategies]\n",
    "    avg_embedding = [np.mean(strategy_metrics[s][\"embedding_times\"]) for s in strategies]\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    plt.bar(x, avg_chunking, width, label='Chunking Time')\n",
    "    plt.bar(x, avg_embedding, width, bottom=avg_chunking, label='Embedding Time')\n",
    "    \n",
    "    plt.title('Average Processing Time Distribution by Strategy')\n",
    "    plt.xlabel('Chunking Strategy')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.xticks(x, strategies, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    time_distribution_plot = os.path.join(metrics_dir, f\"time_distribution_{embedding_model_name.replace('/', '_')}_{num_samples}.png\")\n",
    "    plt.savefig(time_distribution_plot)\n",
    "    plot_paths[\"time_distribution\"] = time_distribution_plot\n",
    "    plt.close()\n",
    "    \n",
    "    # 7. Chunk Size Distribution (Box Plot)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    chunk_size_data = [strategy_metrics[s][\"chunk_sizes\"] for s in strategies]\n",
    "    plt.boxplot(chunk_size_data, labels=strategies)\n",
    "    \n",
    "    plt.title('Chunk Size Distribution by Strategy')\n",
    "    plt.xlabel('Chunking Strategy')\n",
    "    plt.ylabel('Chunk Size (characters)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    size_distribution_plot = os.path.join(metrics_dir, f\"size_distribution_{embedding_model_name.replace('/', '_')}_{num_samples}.png\")\n",
    "    plt.savefig(size_distribution_plot)\n",
    "    plot_paths[\"size_distribution\"] = size_distribution_plot\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a summary plot dashboard\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # 1. Top left: Avg chunks per document\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(strategies, avg_chunks_per_doc)\n",
    "    plt.title('Average Chunks per Document')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Top right: Avg chunk size\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.bar(strategies, avg_chunk_sizes)\n",
    "    plt.title('Average Chunk Size')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 3. Bottom left: Processing time breakdown\n",
    "    plt.subplot(2, 2, 3)\n",
    "    x = np.arange(len(strategies))\n",
    "    plt.bar(x, avg_chunking, width, label='Chunking Time')\n",
    "    plt.bar(x, avg_embedding, width, bottom=avg_chunking, label='Embedding Time')\n",
    "    plt.title('Processing Time Breakdown')\n",
    "    plt.xticks(x, strategies, rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 4. Bottom right: Time per chunk\n",
    "    plt.subplot(2, 2, 4)\n",
    "    time_per_chunk = [np.sum(strategy_metrics[s][\"embedding_times\"])/strategy_metrics[s][\"total_chunks\"] \n",
    "                      if strategy_metrics[s][\"total_chunks\"] > 0 else 0 \n",
    "                      for s in strategies]\n",
    "    plt.bar(strategies, time_per_chunk)\n",
    "    plt.title('Average Time per Chunk')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    dashboard_plot = os.path.join(metrics_dir, f\"metrics_dashboard_{embedding_model_name.replace('/', '_')}_{num_samples}.png\")\n",
    "    plt.savefig(dashboard_plot)\n",
    "    plot_paths[\"dashboard\"] = dashboard_plot\n",
    "    plt.close()\n",
    "    \n",
    "    # Return both database paths and plot paths\n",
    "    return {\n",
    "        \"db_paths\": db_paths,\n",
    "        \"plot_paths\": plot_paths,\n",
    "        \"metrics_csv\": metrics_csv_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fIJyDRDaVauA"
   },
   "outputs": [],
   "source": [
    "def load_vector_dbs(db_paths):\n",
    "    \"\"\"\n",
    "    Load vector databases from disk\n",
    "\n",
    "    Parameters:\n",
    "        db_paths: Dictionary mapping strategy names to file paths\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping strategy names to loaded vector database objects\n",
    "    \"\"\"\n",
    "    vector_dbs = {}\n",
    "\n",
    "    for strategy, path in db_paths.items():\n",
    "        if os.path.exists(path):\n",
    "            print(f\"Loading vector database for {strategy} from {path}\")\n",
    "            try:\n",
    "                with open(path, 'rb') as f:\n",
    "                    vector_dbs[strategy] = pickle.load(f)\n",
    "                print(f\"  Successfully loaded vector database with {len(vector_dbs[strategy].texts)} chunks\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error loading database: {e}\")\n",
    "        else:\n",
    "            print(f\"Vector database for {strategy} not found at {path}\")\n",
    "\n",
    "    return vector_dbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_single_strategy(dataset, strategy_name, db_path=None, \n",
    "                                  question_embedding_model_name=\"BAAI/bge-large-en\", \n",
    "                                  num_samples=20, top_k=5, include_no_context=False):\n",
    "    \"\"\"\n",
    "    Run the experiment using a single pre-built vector database\n",
    "\n",
    "    Parameters:\n",
    "        dataset: The flattened dataset containing documents and questions\n",
    "        strategy_name: Name of the chunking strategy to evaluate\n",
    "        db_path: Path to the vector database file (if None, skips RAG)\n",
    "        question_embedding_model_name: Name of the embedding model to use for questions\n",
    "        num_samples: Number of validation samples to process\n",
    "        top_k: Number of chunks to retrieve\n",
    "        include_no_context: Whether to also run a no-context baseline\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with experiment results for the specified chunking strategy\n",
    "    \"\"\"\n",
    "    # Initialize components\n",
    "    embedding_generator = EmbeddingGenerator(question_embedding_model_name)\n",
    "    llm_generator = LLMGenerator()\n",
    "    evaluator = Evaluator()\n",
    "\n",
    "    # Results storage\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    # Strategies to evaluate\n",
    "    strategies_to_run = []\n",
    "    if strategy_name != \"no_context\":\n",
    "        strategies_to_run.append(strategy_name)\n",
    "    if include_no_context:\n",
    "        strategies_to_run.append(\"no_context\")\n",
    "    \n",
    "    # Load vector database if path is provided\n",
    "    vector_db = None\n",
    "    if db_path is not None and os.path.exists(db_path) and strategy_name != \"no_context\":\n",
    "        print(f\"Loading vector database from {db_path}\")\n",
    "        try:\n",
    "            with open(db_path, 'rb') as f:\n",
    "                vector_db = pickle.load(f)\n",
    "            print(f\"Successfully loaded vector database with {len(vector_db.texts)} chunks\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading database: {e}\")\n",
    "            return results\n",
    "    elif strategy_name != \"no_context\":\n",
    "        print(f\"Vector database path not provided or does not exist for {strategy_name}. Skipping RAG...\")\n",
    "        return results\n",
    "        \n",
    "    validation_samples = dataset[\"train\"][:num_samples]\n",
    "    print(f\"Running experiment on {len(validation_samples)} validation samples with strategy: {strategy_name}\")\n",
    "    if include_no_context:\n",
    "        print(\"Also running no-context baseline for comparison\")\n",
    "\n",
    "    # Track overall metrics\n",
    "    total_correct = 0\n",
    "    total_retrieval_time = 0\n",
    "    total_generation_time = 0\n",
    "    no_context_correct = 0 if include_no_context else None\n",
    "    \n",
    "    # Process each sample\n",
    "    for sample_idx, sample in enumerate(tqdm(validation_samples, desc=\"Processing samples\")):\n",
    "        # Extract data from the flattened sample\n",
    "        context = sample[\"article\"]\n",
    "        question = sample[\"question\"]\n",
    "        options = sample[\"options\"]\n",
    "        gold_answer = sample[\"gold_label\"]  # Should be A, B, C, or D\n",
    "\n",
    "        # Format the question with choices\n",
    "        formatted_question = f\"{question}\\n\"\n",
    "        for i, option_text in enumerate(options):\n",
    "            choice_letter = chr(65 + i)  # A, B, C, D...\n",
    "            formatted_question += f\"{choice_letter}. {option_text}\\n\"\n",
    "\n",
    "        # Process each strategy\n",
    "        for strategy in strategies_to_run:\n",
    "            retrieval_time = 0\n",
    "            retrieved_chunks = []\n",
    "            \n",
    "            print(f\"\\nSample {sample_idx+1}/{len(validation_samples)}, Method: {strategy}\")\n",
    "            \n",
    "            if strategy == \"no_context\":\n",
    "                # Empty context for baseline\n",
    "                combined_context = \"Assume context is not available\"\n",
    "            else:\n",
    "                # Generate question embedding\n",
    "                question_embedding = embedding_generator.generate_question_embedding(formatted_question)\n",
    "    \n",
    "                # Retrieve relevant chunks from the pre-built vector database\n",
    "                start_time = time.time()\n",
    "                _, retrieved_chunks = vector_db.search(question_embedding, k=top_k)\n",
    "                retrieval_time = time.time() - start_time\n",
    "                \n",
    "                # Ensure retrieved_chunks is properly formatted\n",
    "                if isinstance(retrieved_chunks[0], list):\n",
    "                    retrieved_chunks = retrieved_chunks[0]\n",
    "    \n",
    "                # Combine retrieved chunks into a single context\n",
    "                combined_context = \"\\n\\n\".join(retrieved_chunks)\n",
    "    \n",
    "            # Generate answer using LLM\n",
    "            start_time = time.time()\n",
    "            generated_answer = llm_generator.generate_answer(combined_context, formatted_question)\n",
    "            generation_time = time.time() - start_time\n",
    "    \n",
    "            # Evaluate answer\n",
    "            answer_metrics = evaluator.evaluate_answer(generated_answer, gold_answer)\n",
    "            combined_context_separated = \"\\nNEW_CHUNK\\n\".join(retrieved_chunks) if retrieved_chunks else \"\"\n",
    "            \n",
    "            # Update metrics\n",
    "            if strategy == \"no_context\":\n",
    "                no_context_correct += answer_metrics[\"accuracy\"]\n",
    "            else:\n",
    "                total_correct += answer_metrics[\"accuracy\"]\n",
    "                total_retrieval_time += retrieval_time\n",
    "                total_generation_time += generation_time\n",
    "            \n",
    "            # Print detailed output for this sample\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Gold Answer: {gold_answer}\")\n",
    "            print(f\"Generated Answer: {generated_answer}\")\n",
    "            print(f\"Correct: {'Yes' if answer_metrics['accuracy'] == 1 else 'No'}\")\n",
    "            if strategy != \"no_context\":\n",
    "                print(f\"Retrieval Time: {retrieval_time:.4f}s\")\n",
    "            print(f\"Generation Time: {generation_time:.4f}s\")\n",
    "            if strategy != \"no_context\":\n",
    "                print(f\"Retrieved {len(retrieved_chunks)} chunks\")\n",
    "            \n",
    "            # Store results\n",
    "            results[strategy].append({\n",
    "                \"sample_idx\": sample_idx,\n",
    "                \"retrieval_time\": retrieval_time,\n",
    "                \"generation_time\": generation_time,\n",
    "                \"answer_accuracy\": answer_metrics[\"accuracy\"],\n",
    "                \"retrieved_context\": combined_context_separated,\n",
    "                \"question\": formatted_question,\n",
    "                \"generated_answer\": generated_answer,\n",
    "                \"gold_answer\": gold_answer,\n",
    "                \"article_id\": sample[\"article_id\"],\n",
    "                \"title\": sample[\"title\"]\n",
    "            })\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"EXPERIMENT SUMMARY FOR {strategy_name}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total samples: {len(validation_samples)}\")\n",
    "    \n",
    "    if strategy_name != \"no_context\":\n",
    "        accuracy = total_correct / len(validation_samples) if len(validation_samples) > 0 else 0\n",
    "        avg_retrieval_time = total_retrieval_time / len(validation_samples) if len(validation_samples) > 0 else 0\n",
    "        avg_generation_time = total_generation_time / len(validation_samples) if len(validation_samples) > 0 else 0\n",
    "        \n",
    "        print(f\"Strategy: {strategy_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.2%} ({total_correct}/{len(validation_samples)})\")\n",
    "        print(f\"Average Retrieval Time: {avg_retrieval_time:.4f}s\")\n",
    "        print(f\"Average Generation Time: {avg_generation_time:.4f}s\")\n",
    "        print(f\"Average Total Time: {(avg_retrieval_time + avg_generation_time):.4f}s\")\n",
    "    \n",
    "    if include_no_context:\n",
    "        no_context_accuracy = no_context_correct / len(validation_samples) if len(validation_samples) > 0 else 0\n",
    "        print(f\"\\nNo-Context Baseline:\")\n",
    "        print(f\"Accuracy: {no_context_accuracy:.2%} ({no_context_correct}/{len(validation_samples)})\")\n",
    "        \n",
    "        if strategy_name != \"no_context\":\n",
    "            improvement = accuracy - no_context_accuracy\n",
    "            print(f\"\\nImprovement over No-Context: {improvement:.2%}\")\n",
    "            if improvement > 0:\n",
    "                print(f\"RAG with {strategy_name} improved accuracy by {improvement:.2%}\")\n",
    "            elif improvement < 0:\n",
    "                print(f\"RAG with {strategy_name} decreased accuracy by {abs(improvement):.2%}\")\n",
    "            else:\n",
    "                print(f\"RAG with {strategy_name} had no effect on accuracy\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-SCyBlzeIp2-"
   },
   "outputs": [],
   "source": [
    "def run_experiment(dataset, db_paths=None, question_embedding_model_name=\"BAAI/bge-large-en\", num_samples=20, top_k=5):\n",
    "    \"\"\"\n",
    "    Run the experiment using pre-built vector databases\n",
    "\n",
    "    Parameters:\n",
    "        dataset: The flattened dataset containing documents and questions\n",
    "        db_paths: Dictionary mapping strategy names to file paths (if None, generates temp DBs)\n",
    "        model_name: Name of the embedding model to use\n",
    "        num_samples: Number of validation samples to process\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with experiment results for each chunking strategy\n",
    "    \"\"\"\n",
    "    # Initialize components\n",
    "    embedding_generator = EmbeddingGenerator(question_embedding_model_name)\n",
    "    llm_generator = LLMGenerator()\n",
    "    evaluator = Evaluator()\n",
    "\n",
    "    # Results storage\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    # Load vector databases if paths are provided\n",
    "    if db_paths is None:\n",
    "      print(\"NO PATHS PROVIDED! early return\")\n",
    "      return results  # Return empty results if no paths provided\n",
    "    vector_dbs = load_vector_dbs(db_paths)\n",
    "    chunking_strategies = list(vector_dbs.keys())\n",
    "    chunking_strategies.append(\"no_context\") # to eval baseline accuracy without RAG\n",
    "    validation_samples = dataset[\"train\"][:num_samples]\n",
    "    print(f\"Running experiment on {len(validation_samples)} validation samples with {len(chunking_strategies)} chunking strategies (including no-context baseline)\")\n",
    "\n",
    "    # Process each sample\n",
    "    for sample_idx, sample in enumerate(tqdm(validation_samples, desc=\"Processing samples\")):\n",
    "        # Extract data from the flattened sample\n",
    "        context = sample[\"article\"]\n",
    "        question = sample[\"question\"]\n",
    "        options = sample[\"options\"]\n",
    "        gold_answer = sample[\"gold_label\"]  # Should be A, B, C, or D\n",
    "\n",
    "        # Format the question with choices\n",
    "        formatted_question = f\"{question}\\n\"\n",
    "        for i, option_text in enumerate(options):\n",
    "            choice_letter = chr(65 + i)  # A, B, C, D...\n",
    "            formatted_question += f\"{choice_letter}. {option_text}\\n\"\n",
    "\n",
    "        # Process with each chunking method's vector database\n",
    "        for strategy in chunking_strategies:\n",
    "            retrieval_time = 0\n",
    "            retrieved_chunks = []\n",
    "            if strategy not in vector_dbs and strategy!=\"no_context\":\n",
    "                print(f\"Vector database for {strategy} not found. Skipping...\")\n",
    "                continue\n",
    "            print(f\"\\nSample {sample_idx+1}/{len(validation_samples)}, Method: {strategy}\")\n",
    "            if strategy == \"no_context\":\n",
    "                # Empty context for baseline\n",
    "                combined_context = \"Assume context is not available\"\n",
    "            else:\n",
    "                # Generate question embedding\n",
    "                question_embedding = embedding_generator.generate_question_embedding(formatted_question)\n",
    "    \n",
    "                # Retrieve relevant chunks from the pre-built vector database\n",
    "                start_time = time.time()\n",
    "                distances, retrieved_chunks = vector_dbs[strategy].search(question_embedding, k=top_k)\n",
    "                retrieval_time = time.time() - start_time\n",
    "                \n",
    "                # Ensure retrieved_chunks is properly formatted\n",
    "                if isinstance(retrieved_chunks[0], list):\n",
    "                    retrieved_chunks = retrieved_chunks[0]\n",
    "    \n",
    "                # Combine retrieved chunks into a single context\n",
    "                combined_context = \"\\n\\n\".join(retrieved_chunks)\n",
    "    \n",
    "            # Generate answer using LLM\n",
    "            start_time = time.time()\n",
    "            generated_answer = llm_generator.generate_answer(combined_context, formatted_question)\n",
    "            generation_time = time.time() - start_time\n",
    "    \n",
    "            # Evaluate answer\n",
    "            answer_metrics = evaluator.evaluate_answer(generated_answer, gold_answer)\n",
    "            combined_context_separated = \"\\nNEW_CHUNK\\n\".join(retrieved_chunks) if retrieved_chunks else \"\"\n",
    "            # Store results\n",
    "            results[strategy].append({\n",
    "                \"sample_idx\": sample_idx,\n",
    "                \"retrieval_time\": retrieval_time,\n",
    "                \"generation_time\": generation_time,\n",
    "                \"answer_accuracy\": answer_metrics[\"accuracy\"],\n",
    "                \"distances\": distances,\n",
    "                \"retrieved_context\": combined_context_separated,\n",
    "                \"question\": formatted_question,\n",
    "                \"generated_answer\": generated_answer,\n",
    "                \"gold_answer\": gold_answer,\n",
    "                \"article_id\": sample[\"article_id\"],\n",
    "                \"title\": sample[\"title\"]\n",
    "            })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4uU86JFMKWBC"
   },
   "outputs": [],
   "source": [
    "def analyze_results(results):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the experimental results\n",
    "    \"\"\"\n",
    "    # Convert results to DataFrame for easier analysis\n",
    "    all_data = []\n",
    "    for method, method_results in results.items():\n",
    "        for result in method_results:\n",
    "            result_copy = result.copy()\n",
    "            result_copy[\"method\"] = method\n",
    "            all_data.append(result_copy)\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Calculate aggregate metrics 'chunking_time', 'contains_answer', 'embedding_time', 'num_chunks', 'retrieval_precision'\n",
    "    aggregates = df.groupby(\"method\").agg({\n",
    "        \"retrieval_time\": \"mean\",\n",
    "        \"generation_time\": \"mean\",\n",
    "        \"answer_accuracy\": \"mean\"\n",
    "    }).reset_index()\n",
    "\n",
    "    print(\"\\n=== Aggregate Results ===\")\n",
    "    print(aggregates.to_string(index=False))\n",
    "\n",
    "    # Save detailed results to CSV\n",
    "    df.to_csv(\"chunking_experiment_results.csv\", index=False)\n",
    "\n",
    "    # Create visualizations\n",
    "    # Plot accuracy by chunking method\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(aggregates[\"method\"], aggregates[\"answer_accuracy\"])\n",
    "    plt.title(\"Answer Accuracy by Chunking Method\")\n",
    "    plt.xlabel(\"Chunking Method\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"accuracy_by_method.png\")\n",
    "\n",
    "    # Plot processing times by chunking method\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Create a grouped bar chart for different time metrics\n",
    "    bar_width = 0.15\n",
    "    index = np.arange(len(aggregates[\"method\"]))\n",
    "    plt.bar(index + 0.5*bar_width, aggregates[\"retrieval_time\"], bar_width, label=\"Retrieval Time\")\n",
    "    plt.bar(index + 1.5*bar_width, aggregates[\"generation_time\"], bar_width, label=\"Generation Time\")\n",
    "    plt.xlabel(\"Chunking Method\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.title(\"Processing Times by Chunking Method\")\n",
    "    plt.xticks(index, aggregates[\"method\"], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"processing_times.png\")\n",
    "\n",
    "    return df, aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "c3kVjtW5Wq9d"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Load and flatten the QuALITY dataset\n",
    "dataset = load_quality_github_dataset()\n",
    "dataset = flatten_quality_dataset(dataset)\n",
    "\n",
    "# Step 1:Load the wikiQA dataset\n",
    "# dataset = load_wikiqa_dataset()\n",
    "\n",
    "# Step 1:Load the squad dataset\n",
    "#dataset = load_squad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "4JJtRvcIWw-O",
    "outputId": "376039f4-25fd-4db7-f21c-035f34b4eb78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2408/1990588150.py:7: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceBgeEmbeddings(\n",
      "/tmp/ipykernel_2408/3560647892.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vector database for fixed_size_no_overlap...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9909c47c39a946b681013ed3eb21943f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing fixed_size_no_overlap:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database for fixed_size_no_overlap saved to vector_dbs_quality_dataset_300/fixed_size_no_overlap_BAAI_bge-large-en_300.pkl\n",
      "  Total chunks: 300, Avg chunks per doc: 1.00\n",
      "  Total chunking time: 0.18s\n",
      "  Total embedding time: 5.42s\n",
      "Building vector database for fixed_size_with_overlap_10...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bcde0e027c4b0fa511d1e2ecac2d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing fixed_size_with_overlap_10:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database for fixed_size_with_overlap_10 saved to vector_dbs_quality_dataset_300/fixed_size_with_overlap_10_BAAI_bge-large-en_300.pkl\n",
      "  Total chunks: 300, Avg chunks per doc: 1.00\n",
      "  Total chunking time: 0.03s\n",
      "  Total embedding time: 5.24s\n",
      "Building vector database for fixed_size_with_overlap_20...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc78240751647959c09fdd41a7169f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing fixed_size_with_overlap_20:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database for fixed_size_with_overlap_20 saved to vector_dbs_quality_dataset_300/fixed_size_with_overlap_20_BAAI_bge-large-en_300.pkl\n",
      "  Total chunks: 300, Avg chunks per doc: 1.00\n",
      "  Total chunking time: 0.04s\n",
      "  Total embedding time: 5.25s\n",
      "Building vector database for semantic_chunking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f44d90e131f4594a77cec5103a9125a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing semantic_chunking:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database for semantic_chunking saved to vector_dbs_quality_dataset_300/semantic_chunking_BAAI_bge-large-en_300.pkl\n",
      "  Total chunks: 600, Avg chunks per doc: 2.00\n",
      "  Total chunking time: 2.31s\n",
      "  Total embedding time: 6.37s\n",
      "Building vector database for sentence_based_chunking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221e3cff9cac49c787875bcf6646338f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing sentence_based_chunking:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database for sentence_based_chunking saved to vector_dbs_quality_dataset_300/sentence_based_chunking_BAAI_bge-large-en_300.pkl\n",
      "  Total chunks: 762, Avg chunks per doc: 2.54\n",
      "  Total chunking time: 0.01s\n",
      "  Total embedding time: 6.14s\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate and save vector databases (do this once, takes time)\n",
    "db_paths = generate_and_save_vector_dbs(\n",
    "    dataset,\n",
    "    embedding_model_name=\"BAAI/bge-large-en\", #the embedding model used for all the chunking strategies\n",
    "    semantic_model_name=\"all-MiniLM-L6-v2\", #change to use a specific model for semantic chunking\n",
    "    num_samples=1000,\n",
    "    save_dir=\"vectorDB_bge_miniLM_quality_dataset_1000\", #the name should cover all the choices used to build it\n",
    "    force_rebuild=False # Set to True to rebuild even if already exists\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'db_paths': {'fixed_size_no_overlap': 'vector_dbs_quality_dataset_300/fixed_size_no_overlap_BAAI_bge-large-en_300.pkl', 'fixed_size_with_overlap_10': 'vector_dbs_quality_dataset_300/fixed_size_with_overlap_10_BAAI_bge-large-en_300.pkl', 'fixed_size_with_overlap_20': 'vector_dbs_quality_dataset_300/fixed_size_with_overlap_20_BAAI_bge-large-en_300.pkl', 'semantic_chunking': 'vector_dbs_quality_dataset_300/semantic_chunking_BAAI_bge-large-en_300.pkl', 'sentence_based_chunking': 'vector_dbs_quality_dataset_300/sentence_based_chunking_BAAI_bge-large-en_300.pkl'}, 'plot_paths': {'chunking_time': 'vector_dbs_quality_dataset_300/metrics/chunking_time_BAAI_bge-large-en_300.png', 'embedding_time': 'vector_dbs_quality_dataset_300/metrics/embedding_time_BAAI_bge-large-en_300.png', 'chunks_per_doc': 'vector_dbs_quality_dataset_300/metrics/chunks_per_doc_BAAI_bge-large-en_300.png', 'chunk_size': 'vector_dbs_quality_dataset_300/metrics/chunk_size_BAAI_bge-large-en_300.png', 'chunking_vs_chunks': 'vector_dbs_quality_dataset_300/metrics/chunking_vs_chunks_BAAI_bge-large-en_300.png', 'time_distribution': 'vector_dbs_quality_dataset_300/metrics/time_distribution_BAAI_bge-large-en_300.png', 'size_distribution': 'vector_dbs_quality_dataset_300/metrics/size_distribution_BAAI_bge-large-en_300.png', 'dashboard': 'vector_dbs_quality_dataset_300/metrics/metrics_dashboard_BAAI_bge-large-en_300.png'}, 'metrics_csv': 'vector_dbs_quality_dataset_300/metrics/chunking_metrics_BAAI_bge-large-en_300.csv'}\n"
     ]
    }
   ],
   "source": [
    "print(db_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ca4ac18c904bd48e712070811404e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "id": "XpeHqU-wKalq",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7a0382a8cf4b57833ae6110b135854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vector database for fixed_size_no_overlap from vector_dbs_quality_dataset_300/fixed_size_no_overlap_BAAI_bge-large-en_300.pkl\n",
      "  Successfully loaded vector database with 57 chunks\n",
      "Loading vector database for fixed_size_with_overlap_10 from vector_dbs_quality_dataset_300/fixed_size_with_overlap_10_BAAI_bge-large-en_300.pkl\n",
      "  Successfully loaded vector database with 57 chunks\n",
      "Loading vector database for fixed_size_with_overlap_20 from vector_dbs_quality_dataset_300/fixed_size_with_overlap_20_BAAI_bge-large-en_300.pkl\n",
      "  Successfully loaded vector database with 57 chunks\n",
      "Loading vector database for semantic_chunking from vector_dbs_quality_dataset_300/semantic_chunking_BAAI_bge-large-en_300.pkl\n",
      "  Successfully loaded vector database with 114 chunks\n",
      "Loading vector database for sentence_based_chunking from vector_dbs_quality_dataset_300/sentence_based_chunking_BAAI_bge-large-en_300.pkl\n",
      "  Successfully loaded vector database with 145 chunks\n",
      "Running experiment on 100 validation samples with 6 chunking strategies (including no-context baseline)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8842ddb356d24b5499677872cf4844e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing samples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 1/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1/100, Method: semantic_chunking\n",
      "\n",
      "Sample 1/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 1/100, Method: no_context\n",
      "\n",
      "Sample 2/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 2/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 2/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 2/100, Method: semantic_chunking\n",
      "\n",
      "Sample 2/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 2/100, Method: no_context\n",
      "\n",
      "Sample 3/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 3/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 3/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 3/100, Method: semantic_chunking\n",
      "\n",
      "Sample 3/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 3/100, Method: no_context\n",
      "\n",
      "Sample 4/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 4/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 4/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 4/100, Method: semantic_chunking\n",
      "\n",
      "Sample 4/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 4/100, Method: no_context\n",
      "\n",
      "Sample 5/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 5/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 5/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 5/100, Method: semantic_chunking\n",
      "\n",
      "Sample 5/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 5/100, Method: no_context\n",
      "\n",
      "Sample 6/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 6/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 6/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 6/100, Method: semantic_chunking\n",
      "\n",
      "Sample 6/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 6/100, Method: no_context\n",
      "\n",
      "Sample 7/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 7/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 7/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 7/100, Method: semantic_chunking\n",
      "\n",
      "Sample 7/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 7/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 8/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 8/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 8/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 8/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 8/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 8/100, Method: no_context\n",
      "\n",
      "Sample 9/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 9/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 9/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 9/100, Method: semantic_chunking\n",
      "\n",
      "Sample 9/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 9/100, Method: no_context\n",
      "\n",
      "Sample 10/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 10/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 10/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 10/100, Method: semantic_chunking\n",
      "\n",
      "Sample 10/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 10/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 11/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 11/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 11/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 11/100, Method: semantic_chunking\n",
      "\n",
      "Sample 11/100, Method: sentence_based_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 11/100, Method: no_context\n",
      "\n",
      "Sample 12/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 12/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 12/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 12/100, Method: semantic_chunking\n",
      "\n",
      "Sample 12/100, Method: sentence_based_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 12/100, Method: no_context\n",
      "\n",
      "Sample 13/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 13/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 13/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 13/100, Method: semantic_chunking\n",
      "\n",
      "Sample 13/100, Method: sentence_based_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 13/100, Method: no_context\n",
      "\n",
      "Sample 14/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 14/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 14/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 14/100, Method: semantic_chunking\n",
      "\n",
      "Sample 14/100, Method: sentence_based_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 14/100, Method: no_context\n",
      "\n",
      "Sample 15/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 15/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 15/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 15/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 15/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 15/100, Method: no_context\n",
      "\n",
      "Sample 16/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 16/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 16/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 16/100, Method: semantic_chunking\n",
      "\n",
      "Sample 16/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 16/100, Method: no_context\n",
      "\n",
      "Sample 17/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 17/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 17/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 17/100, Method: semantic_chunking\n",
      "\n",
      "Sample 17/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 17/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 18/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 18/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 18/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 18/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 18/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 18/100, Method: no_context\n",
      "\n",
      "Sample 19/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 19/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 19/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 19/100, Method: semantic_chunking\n",
      "\n",
      "Sample 19/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 19/100, Method: no_context\n",
      "\n",
      "Sample 20/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 20/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 20/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 20/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 20/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 20/100, Method: no_context\n",
      "\n",
      "Sample 21/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 21/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 21/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 21/100, Method: semantic_chunking\n",
      "\n",
      "Sample 21/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 21/100, Method: no_context\n",
      "\n",
      "Sample 22/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 22/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 22/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 22/100, Method: semantic_chunking\n",
      "\n",
      "Sample 22/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 22/100, Method: no_context\n",
      "\n",
      "Sample 23/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 23/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 23/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 23/100, Method: semantic_chunking\n",
      "\n",
      "Sample 23/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 23/100, Method: no_context\n",
      "\n",
      "Sample 24/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 24/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 24/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 24/100, Method: semantic_chunking\n",
      "\n",
      "Sample 24/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 24/100, Method: no_context\n",
      "\n",
      "Sample 25/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 25/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 25/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 25/100, Method: semantic_chunking\n",
      "\n",
      "Sample 25/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 25/100, Method: no_context\n",
      "\n",
      "Sample 26/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 26/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 26/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 26/100, Method: semantic_chunking\n",
      "\n",
      "Sample 26/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 26/100, Method: no_context\n",
      "\n",
      "Sample 27/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 27/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 27/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 27/100, Method: semantic_chunking\n",
      "\n",
      "Sample 27/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 27/100, Method: no_context\n",
      "\n",
      "Sample 28/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 28/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 28/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 28/100, Method: semantic_chunking\n",
      "\n",
      "Sample 28/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 28/100, Method: no_context\n",
      "\n",
      "Sample 29/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 29/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 29/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 29/100, Method: semantic_chunking\n",
      "\n",
      "Sample 29/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 29/100, Method: no_context\n",
      "\n",
      "Sample 30/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 30/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 30/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 30/100, Method: semantic_chunking\n",
      "\n",
      "Sample 30/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 30/100, Method: no_context\n",
      "\n",
      "Sample 31/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 31/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 31/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 31/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 31/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 31/100, Method: no_context\n",
      "\n",
      "Sample 32/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 32/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 32/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 32/100, Method: semantic_chunking\n",
      "\n",
      "Sample 32/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 32/100, Method: no_context\n",
      "\n",
      "Sample 33/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 33/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 33/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 33/100, Method: semantic_chunking\n",
      "\n",
      "Sample 33/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 33/100, Method: no_context\n",
      "\n",
      "Sample 34/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 34/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 34/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 34/100, Method: semantic_chunking\n",
      "\n",
      "Sample 34/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 34/100, Method: no_context\n",
      "\n",
      "Sample 35/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 35/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 35/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 35/100, Method: semantic_chunking\n",
      "\n",
      "Sample 35/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 35/100, Method: no_context\n",
      "\n",
      "Sample 36/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 36/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 36/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 36/100, Method: semantic_chunking\n",
      "\n",
      "Sample 36/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 36/100, Method: no_context\n",
      "\n",
      "Sample 37/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 37/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 37/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 37/100, Method: semantic_chunking\n",
      "\n",
      "Sample 37/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 37/100, Method: no_context\n",
      "\n",
      "Sample 38/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 38/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 38/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 38/100, Method: semantic_chunking\n",
      "\n",
      "Sample 38/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 38/100, Method: no_context\n",
      "\n",
      "Sample 39/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 39/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 39/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 39/100, Method: semantic_chunking\n",
      "\n",
      "Sample 39/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 39/100, Method: no_context\n",
      "\n",
      "Sample 40/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 40/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 40/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 40/100, Method: semantic_chunking\n",
      "\n",
      "Sample 40/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 40/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 41/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 41/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 41/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 41/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 41/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 41/100, Method: no_context\n",
      "\n",
      "Sample 42/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 42/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 42/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 42/100, Method: semantic_chunking\n",
      "\n",
      "Sample 42/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 42/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 43/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 43/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 43/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 43/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 43/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 43/100, Method: no_context\n",
      "\n",
      "Sample 44/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 44/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 44/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 44/100, Method: semantic_chunking\n",
      "\n",
      "Sample 44/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 44/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 45/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 45/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 45/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 45/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 45/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 45/100, Method: no_context\n",
      "\n",
      "Sample 46/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 46/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 46/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 46/100, Method: semantic_chunking\n",
      "\n",
      "Sample 46/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 46/100, Method: no_context\n",
      "\n",
      "Sample 47/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 47/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 47/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 47/100, Method: semantic_chunking\n",
      "\n",
      "Sample 47/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 47/100, Method: no_context\n",
      "\n",
      "Sample 48/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 48/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 48/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 48/100, Method: semantic_chunking\n",
      "\n",
      "Sample 48/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 48/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 49/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 49/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 49/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 49/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 49/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 49/100, Method: no_context\n",
      "\n",
      "Sample 50/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 50/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 50/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 50/100, Method: semantic_chunking\n",
      "\n",
      "Sample 50/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 50/100, Method: no_context\n",
      "\n",
      "Sample 51/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 51/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 51/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 51/100, Method: semantic_chunking\n",
      "\n",
      "Sample 51/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 51/100, Method: no_context\n",
      "\n",
      "Sample 52/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 52/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 52/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 52/100, Method: semantic_chunking\n",
      "\n",
      "Sample 52/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 52/100, Method: no_context\n",
      "\n",
      "Sample 53/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 53/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 53/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 53/100, Method: semantic_chunking\n",
      "\n",
      "Sample 53/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 53/100, Method: no_context\n",
      "\n",
      "Sample 54/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 54/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 54/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 54/100, Method: semantic_chunking\n",
      "\n",
      "Sample 54/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 54/100, Method: no_context\n",
      "\n",
      "Sample 55/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 55/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 55/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 55/100, Method: semantic_chunking\n",
      "\n",
      "Sample 55/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 55/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 56/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 56/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 56/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 56/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 56/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 56/100, Method: no_context\n",
      "\n",
      "Sample 57/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 57/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 57/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 57/100, Method: semantic_chunking\n",
      "\n",
      "Sample 57/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 57/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 58/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 58/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 58/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 58/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 58/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 58/100, Method: no_context\n",
      "\n",
      "Sample 59/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 59/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 59/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 59/100, Method: semantic_chunking\n",
      "\n",
      "Sample 59/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 59/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 60/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 60/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 60/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 60/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 60/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 60/100, Method: no_context\n",
      "\n",
      "Sample 61/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 61/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 61/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 61/100, Method: semantic_chunking\n",
      "\n",
      "Sample 61/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 61/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 62/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 62/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 62/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 62/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 62/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 62/100, Method: no_context\n",
      "\n",
      "Sample 63/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 63/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 63/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 63/100, Method: semantic_chunking\n",
      "\n",
      "Sample 63/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 63/100, Method: no_context\n",
      "\n",
      "Sample 64/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 64/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 64/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 64/100, Method: semantic_chunking\n",
      "\n",
      "Sample 64/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 64/100, Method: no_context\n",
      "\n",
      "Sample 65/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 65/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 65/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 65/100, Method: semantic_chunking\n",
      "\n",
      "Sample 65/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 65/100, Method: no_context\n",
      "\n",
      "Sample 66/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 66/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 66/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 66/100, Method: semantic_chunking\n",
      "\n",
      "Sample 66/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 66/100, Method: no_context\n",
      "\n",
      "Sample 67/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 67/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 67/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 67/100, Method: semantic_chunking\n",
      "\n",
      "Sample 67/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 67/100, Method: no_context\n",
      "\n",
      "Sample 68/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 68/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 68/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 68/100, Method: semantic_chunking\n",
      "\n",
      "Sample 68/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 68/100, Method: no_context\n",
      "\n",
      "Sample 69/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 69/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 69/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 69/100, Method: semantic_chunking\n",
      "\n",
      "Sample 69/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 69/100, Method: no_context\n",
      "\n",
      "Sample 70/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 70/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 70/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 70/100, Method: semantic_chunking\n",
      "\n",
      "Sample 70/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 70/100, Method: no_context\n",
      "\n",
      "Sample 71/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 71/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 71/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 71/100, Method: semantic_chunking\n",
      "\n",
      "Sample 71/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 71/100, Method: no_context\n",
      "\n",
      "Sample 72/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 72/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 72/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 72/100, Method: semantic_chunking\n",
      "\n",
      "Sample 72/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 72/100, Method: no_context\n",
      "\n",
      "Sample 73/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 73/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 73/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 73/100, Method: semantic_chunking\n",
      "\n",
      "Sample 73/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 73/100, Method: no_context\n",
      "\n",
      "Sample 74/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 74/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 74/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 74/100, Method: semantic_chunking\n",
      "\n",
      "Sample 74/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 74/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 75/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 75/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 75/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 75/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 75/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 75/100, Method: no_context\n",
      "\n",
      "Sample 76/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 76/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 76/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 76/100, Method: semantic_chunking\n",
      "\n",
      "Sample 76/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 76/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 77/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 77/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 77/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 77/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 77/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 77/100, Method: no_context\n",
      "\n",
      "Sample 78/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 78/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 78/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 78/100, Method: semantic_chunking\n",
      "\n",
      "Sample 78/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 78/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 79/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 79/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 79/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 79/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 79/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 79/100, Method: no_context\n",
      "\n",
      "Sample 80/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 80/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 80/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 80/100, Method: semantic_chunking\n",
      "\n",
      "Sample 80/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 80/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 81/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 81/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 81/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 81/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 81/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 81/100, Method: no_context\n",
      "\n",
      "Sample 82/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 82/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 82/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 82/100, Method: semantic_chunking\n",
      "\n",
      "Sample 82/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 82/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 83/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 83/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 83/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 83/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 83/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 83/100, Method: no_context\n",
      "\n",
      "Sample 84/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 84/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 84/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 84/100, Method: semantic_chunking\n",
      "\n",
      "Sample 84/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 84/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 85/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 85/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 85/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 85/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 85/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 85/100, Method: no_context\n",
      "\n",
      "Sample 86/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 86/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 86/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 86/100, Method: semantic_chunking\n",
      "\n",
      "Sample 86/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 86/100, Method: no_context\n",
      "\n",
      "Sample 87/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 87/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 87/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 87/100, Method: semantic_chunking\n",
      "\n",
      "Sample 87/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 87/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 88/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 88/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 88/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 88/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 88/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 88/100, Method: no_context\n",
      "\n",
      "Sample 89/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 89/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 89/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 89/100, Method: semantic_chunking\n",
      "\n",
      "Sample 89/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 89/100, Method: no_context\n",
      "\n",
      "Sample 90/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 90/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 90/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 90/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 90/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 90/100, Method: no_context\n",
      "\n",
      "Sample 91/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 91/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 91/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 91/100, Method: semantic_chunking\n",
      "\n",
      "Sample 91/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 91/100, Method: no_context\n",
      "\n",
      "Sample 92/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 92/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 92/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 92/100, Method: semantic_chunking\n",
      "\n",
      "Sample 92/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 92/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 93/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 93/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 93/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 93/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 93/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 93/100, Method: no_context\n",
      "\n",
      "Sample 94/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 94/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 94/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 94/100, Method: semantic_chunking\n",
      "\n",
      "Sample 94/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 94/100, Method: no_context\n",
      "\n",
      "Sample 95/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 95/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 95/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 95/100, Method: semantic_chunking\n",
      "\n",
      "Sample 95/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 95/100, Method: no_context\n",
      "\n",
      "Sample 96/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 96/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 96/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 96/100, Method: semantic_chunking\n",
      "\n",
      "Sample 96/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 96/100, Method: no_context\n",
      "\n",
      "Sample 97/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 97/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 97/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 97/100, Method: semantic_chunking\n",
      "\n",
      "Sample 97/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 97/100, Method: no_context\n",
      "\n",
      "Sample 98/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 98/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 98/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 98/100, Method: semantic_chunking\n",
      "\n",
      "Sample 98/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 98/100, Method: no_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 99/100, Method: fixed_size_no_overlap\n",
      "\n",
      "Sample 99/100, Method: fixed_size_with_overlap_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 99/100, Method: fixed_size_with_overlap_20\n",
      "\n",
      "Sample 99/100, Method: semantic_chunking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 99/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 99/100, Method: no_context\n",
      "\n",
      "Sample 100/100, Method: fixed_size_no_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 100/100, Method: fixed_size_with_overlap_10\n",
      "\n",
      "Sample 100/100, Method: fixed_size_with_overlap_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 100/100, Method: semantic_chunking\n",
      "\n",
      "Sample 100/100, Method: sentence_based_chunking\n",
      "\n",
      "Sample 100/100, Method: no_context\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run experiments using the pre-built databases\n",
    "results = run_experiment(\n",
    "    dataset,\n",
    "    db_paths=db_paths[\"db_paths\"],\n",
    "    question_embedding_model_name=\"BAAI/bge-large-en\", #model used just to generate the question embeddings\n",
    "    num_samples=100,  # Number of samples to run inference on\n",
    "    top_k=5 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "id": "CIwFiKzeW-RW",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Aggregate Results ===\n",
      "                    method  retrieval_time  generation_time  answer_accuracy\n",
      "     fixed_size_no_overlap        0.000051         0.107780             0.98\n",
      "fixed_size_with_overlap_10        0.000049         0.104209             0.98\n",
      "fixed_size_with_overlap_20        0.000050         0.104118             0.98\n",
      "                no_context        0.000000         0.033073             0.84\n",
      "         semantic_chunking        0.000067         0.073545             0.97\n",
      "   sentence_based_chunking        0.000076         0.056960             0.96\n",
      "\n",
      "Experiment completed! Results saved to chunking_experiment_results.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Step 4: Analyze and visualize results\n",
    "df, aggregates = analyze_results(results)\n",
    "print(\"\\nExperiment completed! Results saved to chunking_experiment_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
